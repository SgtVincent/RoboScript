{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Failed to import pyassimp, see https://github.com/ros-planning/moveit/issues/86 for more info\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "from scipy.spatial.transform import Rotation as R \n",
    "import open3d as o3d \n",
    "# add catkin_ws context \n",
    "sys.path.append(\"/home/junting/catkin_ws/devel/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/junting/franka_ws/devel/lib/python3.9/site-packages\")\n",
    "\n",
    "from src.lmp import *\n",
    "from src.env.true_grounding_env import TrueGroundingEnv\n",
    "from src.configs.config import load_config\n",
    "cfg_tabletop = load_config(\"text_gpt_3.yaml\")\n",
    "import rospy \n",
    "import rospkg\n",
    "import jupyros as jr\n",
    "\n",
    "from std_msgs.msg import String, Header\n",
    "from geometry_msgs.msg import PoseStamped, Pose, Point, Quaternion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] [1710246434.111063, 0.000000]: init_node, name[/eval_code], pid[217405]\n",
      "[DEBUG] [1710246434.112169, 0.000000]: binding to 0.0.0.0 0\n",
      "[DEBUG] [1710246434.112918, 0.000000]: bound to 0.0.0.0 43919\n",
      "[DEBUG] [1710246434.113120, 0.000000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246434.113900, 0.000000]: ... service URL is rosrpc://junting-PC:43919\n",
      "[DEBUG] [1710246434.114779, 0.000000]: [/eval_code/get_loggers]: new Service instance\n",
      "[DEBUG] [1710246434.116069, 1021.765000]: ... service URL is rosrpc://junting-PC:43919\n",
      "[DEBUG] [1710246434.116748, 1021.766000]: [/eval_code/set_logger_level]: new Service instance\n",
      "[DEBUG] [1710246434.285780, 1021.934000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246434.287642, 1021.936000]: connecting to junting-PC 59295\n",
      "[INFO] [1710246434.288168, 1021.936000]: camera_left: Waiting for camera_left/color/camera_info...\n",
      "[DEBUG] [1710246434.289894, 1021.938000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246434.290556, 1021.939000]: connecting to junting-PC 59295\n",
      "[INFO] [1710246434.790870, 1022.439000]: camera_left: camera_left/color/camera_info received!\n",
      "[INFO] [1710246434.791759, 1022.439000]: camera_left: camera_left/depth/camera_info received!\n",
      "[DEBUG] [1710246434.795330, 1022.443000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246434.797048, 1022.445000]: connecting to junting-PC 38055\n",
      "[INFO] [1710246434.797301, 1022.445000]: camera_right: Waiting for camera_right/color/camera_info...\n",
      "[DEBUG] [1710246434.799520, 1022.447000]: connecting to junting-PC 38055\n",
      "[DEBUG] [1710246434.799782, 1022.447000]: connecting to junting-PC 44099\n",
      "[INFO] [1710246435.300902, 1022.947000]: camera_right: camera_right/color/camera_info received!\n",
      "[INFO] [1710246435.302032, 1022.948000]: camera_right: camera_right/depth/camera_info received!\n",
      "[DEBUG] [1710246435.306394, 1022.952000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246435.308043, 1022.954000]: connecting to junting-PC 55441\n",
      "[INFO] [1710246435.308415, 1022.954000]: camera_top: Waiting for camera_top/color/camera_info...\n",
      "[DEBUG] [1710246435.310352, 1022.956000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246435.310795, 1022.956000]: connecting to junting-PC 55441\n",
      "[INFO] [1710246435.826560, 1023.456000]: camera_top: camera_top/color/camera_info received!\n",
      "[INFO] [1710246435.827771, 1023.457000]: camera_top: camera_top/depth/camera_info received!\n",
      "[DEBUG] [1710246435.829148, 1023.458000]: ... service URL is rosrpc://junting-PC:43919\n",
      "[DEBUG] [1710246435.829817, 1023.459000]: [/eval_code/tf2_frames]: new Service instance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rospack] Error: package 'franka_umi_description' not found\n",
      "[librospack]: error while executing command\n",
      "\u001b[31m[ERROR] [1710246436.438037634, 1024.066000000]: Error retrieving file [package://franka_umi_description/meshes/hand.STL]: Package [franka_umi_description] does not exist\u001b[0m\n",
      "\u001b[33m[ WARN] [1710246436.438082327, 1024.066000000]: Link panda_hand has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n",
      "[rospack] Error: package 'franka_umi_description' not found\n",
      "[librospack]: error while executing command\n",
      "\u001b[31m[ERROR] [1710246436.720333716, 1024.346000000]: Error retrieving file [package://franka_umi_description/meshes/left_finger.STL]: Package [franka_umi_description] does not exist\u001b[0m\n",
      "\u001b[33m[ WARN] [1710246436.720365376, 1024.346000000]: Link panda_leftfinger has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n",
      "[rospack] Error: package 'franka_umi_description' not found\n",
      "[librospack]: error while executing command\n",
      "\u001b[31m[ERROR] [1710246437.004824709, 1024.631000000]: Error retrieving file [package://franka_umi_description/meshes/right_finger.STL]: Package [franka_umi_description] does not exist\u001b[0m\n",
      "\u001b[33m[ WARN] [1710246437.004859345, 1024.631000000]: Link panda_rightfinger has visual geometry but no collision geometry. Collision geometry will be left empty. Fix your URDF file by explicitly specifying collision geometry.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m[ INFO] [1710246435.845439087]: Loading robot model 'panda'...\u001b[0m\n",
      "\u001b[0m[ INFO] [1710246435.845955352]: No root/virtual joint specified in SRDF. Assuming fixed joint\u001b[0m\n",
      "[DEBUG] [1710246437.050700, 1024.672000]: connecting to junting-PC 57775\n",
      "[DEBUG] [1710246437.054899, 1024.672000]: connecting to ('junting-PC', 45337)\n",
      "[DEBUG] [1710246437.058045, 1024.674000]: connecting to junting-PC 58097\n",
      "[DEBUG] [1710246437.070664, 1024.686000]: connecting to junting-PC 44099\n",
      "\u001b[0m[ INFO] [1710246438.036924237, 1025.652000000]: Ready to take commands for planning group panda_manipulator.\u001b[0m\n",
      "\u001b[0m[ INFO] [1710246438.454867918, 1026.069000000]: Ready to take commands for planning group panda_hand.\u001b[0m\n",
      "[DEBUG] [1710246438.461970, 1025.650000]: connecting to junting-PC 48471\n",
      "[DEBUG] [1710246438.463618, 1026.071000]: connecting to junting-PC 58097\n",
      "[DEBUG] [1710246438.467734, 1026.079000]: connecting to junting-PC 57775\n",
      "[DEBUG] [1710246438.509856, 1026.116000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.543387, 1026.151000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.545008, 1026.153000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.548715, 1026.156000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.566530, 1026.174000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.572062, 1026.178000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.587898, 1026.190000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.599586, 1026.207000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.610426, 1026.218000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.614574, 1026.222000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.660047, 1026.265000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.665078, 1026.269000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.666185, 1026.271000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.675071, 1026.280000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.681458, 1026.286000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.681872, 1026.286000]: connecting to junting-PC 44099\n",
      "Gripper action clients ready\n",
      "[DEBUG] [1710246438.928792, 1026.527000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.935184, 1026.533000]: connecting to junting-PC 44099\n",
      "[DEBUG] [1710246438.937873, 1026.536000]: connecting to junting-PC 44099\n",
      "Set up Franka API. Ready to go!\n",
      "[DEBUG] [1710246438.942612, 1026.541000]: connecting to ('junting-PC', 38423)\n",
      "[INFO] [1710246438.943602, 1026.542000]: Grasp detection: remote model service ready\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# initialize environment\n",
    "########################################\n",
    "rospy.init_node('eval_code', log_level=rospy.DEBUG)\n",
    "# get package root path \n",
    "pkg_root = rospkg.RosPack().get_path('instruct_to_policy')\n",
    "\n",
    "# setup environment\n",
    "env = TrueGroundingEnv(cfg_tabletop)\n",
    "# env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFound",
     "evalue": "franka_umi_description\nROS path [0]=/home/junting/miniconda3/envs/ros_env/share/ros\nROS path [1]=/home/junting/catkin_ws/src/llm-manipulation-bench/franka_policy\nROS path [2]=/home/junting/catkin_ws/src/llm-manipulation-bench/grasp_detection\nROS path [3]=/home/junting/catkin_ws/src/llm-manipulation-bench/joint_prediction\nROS path [4]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/panda_moveit_config\nROS path [5]=/home/junting/catkin_ws/src/llm-manipulation-bench/gazebo_plugins_local\nROS path [6]=/home/junting/catkin_ws/src/perception_pcl/pcl_conversions\nROS path [7]=/home/junting/catkin_ws/src/perception_pcl/pcl_ros\nROS path [8]=/home/junting/catkin_ws/src/moveit_tutorials\nROS path [9]=/home/junting/catkin_ws/src/perception_pcl/perception_pcl\nROS path [10]=/home/junting/catkin_ws/src/llm-manipulation-bench/realsense_gazebo_plugin\nROS path [11]=/home/junting/catkin_ws/src/llm-manipulation-bench/instruct_to_policy\nROS path [12]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/robotiq/robotiq_description\nROS path [13]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/robotiq/robotiq_gazebo\nROS path [14]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/universal_robots\nROS path [15]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur5_gripper_moveit_config\nROS path [16]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/ur5_motion_planning\nROS path [17]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/ur5_robotiq85_moveit_config\nROS path [18]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_bringup\nROS path [19]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_description\nROS path [20]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_driver\nROS path [21]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_e_description\nROS path [22]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_e_gazebo\nROS path [23]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_gazebo\nROS path [24]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_kinematics\nROS path [25]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_msgs\nROS path [26]=/home/junting/miniconda3/envs/ros_env/share",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFound\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrospkg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRosPack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfranka_umi_description\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ros_env/lib/python3.9/site-packages/rospkg/rospack.py:207\u001b[0m, in \u001b[0;36mManifestManager.get_path\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_location_cache()\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_location_cache:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResourceNotFound(name, ros_paths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ros_paths)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_location_cache[name]\n",
      "\u001b[0;31mResourceNotFound\u001b[0m: franka_umi_description\nROS path [0]=/home/junting/miniconda3/envs/ros_env/share/ros\nROS path [1]=/home/junting/catkin_ws/src/llm-manipulation-bench/franka_policy\nROS path [2]=/home/junting/catkin_ws/src/llm-manipulation-bench/grasp_detection\nROS path [3]=/home/junting/catkin_ws/src/llm-manipulation-bench/joint_prediction\nROS path [4]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/panda_moveit_config\nROS path [5]=/home/junting/catkin_ws/src/llm-manipulation-bench/gazebo_plugins_local\nROS path [6]=/home/junting/catkin_ws/src/perception_pcl/pcl_conversions\nROS path [7]=/home/junting/catkin_ws/src/perception_pcl/pcl_ros\nROS path [8]=/home/junting/catkin_ws/src/moveit_tutorials\nROS path [9]=/home/junting/catkin_ws/src/perception_pcl/perception_pcl\nROS path [10]=/home/junting/catkin_ws/src/llm-manipulation-bench/realsense_gazebo_plugin\nROS path [11]=/home/junting/catkin_ws/src/llm-manipulation-bench/instruct_to_policy\nROS path [12]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/robotiq/robotiq_description\nROS path [13]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/robotiq/robotiq_gazebo\nROS path [14]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/universal_robots\nROS path [15]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur5_gripper_moveit_config\nROS path [16]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/ur5_motion_planning\nROS path [17]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/ur5_robotiq85_moveit_config\nROS path [18]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_bringup\nROS path [19]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_description\nROS path [20]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_driver\nROS path [21]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_e_description\nROS path [22]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_e_gazebo\nROS path [23]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_gazebo\nROS path [24]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_kinematics\nROS path [25]=/home/junting/catkin_ws/src/llm-manipulation-bench/moveit_configs/ur5_package/universal_robot/ur_msgs\nROS path [26]=/home/junting/miniconda3/envs/ros_env/share"
     ]
    }
   ],
   "source": [
    " rospkg.RosPack().get_path(\"franka_umi_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shutdown request: [/eval_code] Reason: new node registered with same name\n",
      "[DEBUG] [1710245730.410098, 322.478000]: [/clock] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.410662, 322.478000]: [/camera_left/color/image_raw] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.412464, 322.478000]: [/camera_left/aligned_depth/image_raw] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.412886, 322.478000]: [/camera_left/color/camera_info] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.413273, 322.478000]: [/camera_left/aligned_depth/camera_info] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.413856, 322.478000]: [/camera_right/color/image_raw] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.414367, 322.478000]: [/camera_right/aligned_depth/image_raw] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.414527, 322.478000]: [/camera_right/color/camera_info] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.415235, 322.478000]: [/camera_right/aligned_depth/camera_info] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.416944, 322.478000]: [/camera_top/color/image_raw] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.417160, 322.478000]: [/camera_top/aligned_depth/image_raw] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.417532, 322.478000]: [/camera_top/color/camera_info] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.418141, 322.478000]: [/camera_top/aligned_depth/camera_info] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.418579, 322.478000]: [/tf] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.418802, 322.478000]: [/tf] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.418971, 322.478000]: [/tf] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.419146, 322.478000]: [/tf_static] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.419586, 322.478000]: [/tf_static] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.420128, 322.478000]: [/tf_static] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.420436, 322.478000]: [/franka_gripper/joint_states] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.420994, 322.478000]: [/franka_gripper/homing/status] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.421160, 322.478000]: [/franka_gripper/homing/result] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.421628, 322.478000]: [/franka_gripper/homing/feedback] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.421763, 322.478000]: [/franka_gripper/grasp/status] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.422313, 322.478000]: [/franka_gripper/grasp/result] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.422693, 322.478000]: [/franka_gripper/grasp/feedback] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.423187, 322.478000]: [/franka_gripper/move/status] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.423481, 322.478000]: [/franka_gripper/move/result] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.424176, 322.478000]: [/franka_gripper/move/feedback] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.424537, 322.478000]: [/franka_gripper/gripper_action/status] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.424919, 322.478000]: [/franka_gripper/gripper_action/result] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.425343, 322.478000]: [/franka_gripper/gripper_action/feedback] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.425675, 322.478000]: [/franka_gripper/stop/status] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.426126, 322.478000]: [/franka_gripper/stop/result] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.427136, 322.478000]: [/franka_gripper/stop/feedback] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.427532, 322.478000]: [/franka_control/error_recovery/status] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.427822, 322.478000]: [/franka_control/error_recovery/result] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.428269, 322.478000]: [/franka_control/error_recovery/feedback] failed to receive incoming message : unable to receive data from sender, check sender's logs for details\n",
      "[DEBUG] [1710245730.503685, 322.478000]: TCPServer[42895] shutting down\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from src.utils import prepare_vars\n",
    "# vars, _ = prepare_vars(env)\n",
    "# locals().update(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_grasp_pose = env.parse_horizontal_grasp_pose(\"cabinet.handle_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.grasp(handle_grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] [1710245820.251121, 322.478000]: MoveitEnv: wait for open_gripper 0-th time.....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.open_gripper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth perception and 3D fusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D fusion \n",
    "from src.perception.scene_manager import SceneManager\n",
    "sensor_data = env.get_sensor_data()\n",
    "sensor_data['detections_list'] = [{},{},{}]\n",
    "\n",
    "scene_manager = SceneManager()\n",
    "scene_manager.update_fusion(sensor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cropped point cloud\n",
    "# drawer_bbox = env.get_3d_bbox('cabinet.drawer_0')\n",
    "# drawer_pcd = scene_manager.scene_tsdf_full.crop_cloud(\n",
    "#     crop_center=(drawer_bbox[:3] + drawer_bbox[3:]) / 2,\n",
    "#     crop_size=(drawer_bbox[3:] - drawer_bbox[:3])\n",
    "# )\n",
    "# cabinet_bbox = env.get_3d_bbox('cabinet')\n",
    "# cabinet_pcd = scene_manager.scene_tsdf_full.crop_cloud(\n",
    "#     crop_center=(cabinet_bbox[:3] + cabinet_bbox[3:]) / 2,\n",
    "#     crop_size=(cabinet_bbox[3:] - cabinet_bbox[:3])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d \n",
    "# o3d.io.write_point_cloud(os.path.join(pkg_root, 'data', 'drawer.pcd'), drawer_pcd)\n",
    "# o3d.io.write_point_cloud(os.path.join(pkg_root, 'data', 'cabinet.pcd'), cabinet_pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick and Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.get_robot_base_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] [1710246567.893741, 1070.037000]: connecting to junting-PC 44099\n"
     ]
    },
    {
     "ename": "ServiceException",
     "evalue": "service [/gazebo/get_joint_properties] returned no response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_joint_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ros_env/lib/python3.9/site-packages/rospy/impl/tcpros_service.py:442\u001b[0m, in \u001b[0;36mServiceProxy.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03m    Callable-style version of the service API. This accepts either a request message instance,\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    or you can call directly with arguments to create a new request instance. e.g.::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    message. This is usually a type error with one of the fields.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ros_env/lib/python3.9/site-packages/rospy/impl/tcpros_service.py:525\u001b[0m, in \u001b[0;36mServiceProxy.call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    523\u001b[0m responses \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mreceive_once()\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] returned no response\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolved_name)\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] returned multiple responses: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolved_name, \u001b[38;5;28mlen\u001b[39m(responses)))\n",
      "\u001b[0;31mServiceException\u001b[0m: service [/gazebo/get_joint_properties] returned no response"
     ]
    }
   ],
   "source": [
    "env.get_joint_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] [1710246038.977995, 322.478000]: connecting to junting-PC 44099\n"
     ]
    },
    {
     "ename": "ServiceException",
     "evalue": "service [/gazebo/get_bounding_boxes] returned no response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pose_msg \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_adaptive_shape_grasp_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/catkin_ws/src/llm-manipulation-bench/instruct_to_policy/scripts/src/env/env.py:146\u001b[0m, in \u001b[0;36mEnv.parse_adaptive_shape_grasp_pose\u001b[0;34m(self, object_name, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_adaptive_shape_grasp_pose\u001b[39m(\u001b[38;5;28mself\u001b[39m, object_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mPose:\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    Parse grasp pose for the object. Use ground truth grounding and grasp detection model.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m        description: str, description of the pose\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     object_bbox \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_3d_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m    147\u001b[0m     description:\u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# get visual input from perception model\u001b[39;00m\n",
      "File \u001b[0;32m~/catkin_ws/src/llm-manipulation-bench/instruct_to_policy/scripts/src/env/true_grounding_env.py:64\u001b[0m, in \u001b[0;36mTrueGroundingEnv.get_3d_bbox\u001b[0;34m(self, object_name, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_3d_bbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, object_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mnp\u001b[38;5;241m.\u001b[39marray:\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    Get the 3D bounding box of the object in the world frame.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    This function uses ground truth model state from gazebo and ignore all other parameters.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    Return [x_min, y_min, z_min, x_max, y_max, z_max]\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     center, size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_gt_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m center \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/catkin_ws/src/llm-manipulation-bench/instruct_to_policy/scripts/src/env/gazebo_env.py:130\u001b[0m, in \u001b[0;36mGazeboEnv.get_gt_bbox\u001b[0;34m(self, object_name)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gt_bbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, object_name)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mTuple[np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Get object bounding box.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgazebo_gt_bboxes:List[BoundingBox3D] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bounding_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbboxes_3d\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# gt bbox of drawer or handle: need to convert to link name\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcabinet.drawer\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m object_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcabinet.handle\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m object_name:\n",
      "File \u001b[0;32m~/miniconda3/envs/ros_env/lib/python3.9/site-packages/rospy/impl/tcpros_service.py:442\u001b[0m, in \u001b[0;36mServiceProxy.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03m    Callable-style version of the service API. This accepts either a request message instance,\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    or you can call directly with arguments to create a new request instance. e.g.::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    message. This is usually a type error with one of the fields.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ros_env/lib/python3.9/site-packages/rospy/impl/tcpros_service.py:525\u001b[0m, in \u001b[0;36mServiceProxy.call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    523\u001b[0m responses \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mreceive_once()\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] returned no response\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolved_name)\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] returned multiple responses: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolved_name, \u001b[38;5;28mlen\u001b[39m(responses)))\n",
      "\u001b[0;31mServiceException\u001b[0m: service [/gazebo/get_bounding_boxes] returned no response"
     ]
    }
   ],
   "source": [
    "pose_msg = env.parse_adaptive_shape_grasp_pose(\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.grasp(pose_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.get_obj_name_list()\n",
    "env.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.attach_object(\"white_and_yellow_mug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_pose = env.parse_place_pose(object_name=\"white_and_yellow_mug\", receptacle_name=\"cabinet.drawer_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.publish_goal_to_marker(place_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.move_group.place(\"white_and_yellow_mug\", place_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.publish_goal_to_marker(approach_pose)\n",
    "env.move_to_pose(approach_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close_gripper(width=0.05, force=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.attach_object(\"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_pose = env.parse_place_pose(object_name=\"apple\", receptacle_name=\"white_ceramic_plate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.move_to_pose(place_pose)\n",
    "env.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.detach_object(\"apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Drawer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jr.publish('/rviz/moveit/move_marker/goal_panda_hand_tcp', PoseStamped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "# env.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.get_obj_name_list()\n",
    "# [bbox.object_id for bbox in env.gazebo_gt_bboxes]\n",
    "env.get_3d_bbox(\"cabinet.handle_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_pose = env.parse_adaptive_shape_grasp_pose(object_name=\"cabinet.handle_0\")\n",
    "print(grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.publish_goal_to_marker(grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.grasp(grasp_pose)\n",
    "# env.move_to_pose(grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a horizontal trajectory to open the drawer\n",
    "grasp_position = np.array([grasp_pose.position.x, grasp_pose.position.y, grasp_pose.position.z])\n",
    "pull_position = grasp_position + np.array([0.2, 0, 0]).astype(float)\n",
    "pull_pose = Pose(position=Point(*pull_position), orientation=grasp_pose.orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.move_to_pose(pull_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different grasp depth \n",
    "pose_msg = env.parse_adaptive_shape_grasp_pose(object_name=\"apple\")\n",
    "\n",
    "rot_mat = R.from_quat([pose_msg.orientation.x, pose_msg.orientation.y, pose_msg.orientation.z, pose_msg.orientation.w]).as_matrix()\n",
    "translation = np.array([pose_msg.position.x, pose_msg.position.y, pose_msg.position.z])\n",
    "\n",
    "depth = 0.05\n",
    "\n",
    "pregrasp_offset_local = np.array([0, 0, -0.15]).astype(np.float32)\n",
    "# predicted gripper center is 0.02m above the gripper tip\n",
    "approach_offset_local = np.array([0, 0, depth - 0.02 ]).astype(np.float32)\n",
    "pregrasp_position = translation + rot_mat @ pregrasp_offset_local\n",
    "approach_position = translation + rot_mat @ approach_offset_local\n",
    "\n",
    "pregrasp_pose = Pose(position=Point(*pregrasp_position), orientation=pose_msg.orientation)\n",
    "approach_pose = Pose(position=Point(*approach_position), orientation=pose_msg.orientation)\n",
    " \n",
    "env.open_gripper()\n",
    " \n",
    "# env.publish_goal_to_marker(pregrasp_pose)\n",
    "env.move_to_pose(pregrasp_pose)\n",
    "# env.publish_goal_to_marker(approach_pose)\n",
    "env.move_to_pose(approach_pose)\n",
    "env.close_gripper(width=0.05, force=30)\n",
    "env.attach_object(\"apple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grasp preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspnetAPI import GraspGroup, Grasp\n",
    "from grasp_detection.msg import Grasp as GraspMsg\n",
    "from src.grasp_detection.utils import select_grasp_by_preference\n",
    "\n",
    "# reload src.grasp_detection.utils \n",
    "import importlib\n",
    "importlib.reload(sys.modules['src.grasp_detection.utils'])\n",
    "from src.grasp_detection.utils import select_grasp_by_preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_name = \"white_and_pink_box\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth preference of object \n",
    "\n",
    "# preferred_position is the center of the object\n",
    "preferred_position = env.get_object_center_position(object_name)\n",
    "\n",
    "# preferred_orientation is table surface \n",
    "preferred_plane_normal = np.array([0, 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually call grasp detection model to get list of grasps\n",
    "\n",
    "object_bbox = env.get_3d_bbox(object_name)    \n",
    "sensor_data = env.get_sensor_data()\n",
    "\n",
    "object_pcd = scene_manager.scene_tsdf_full.crop_cloud(\n",
    "    crop_center=(object_bbox[:3] + object_bbox[3:]) / 2,\n",
    "    crop_size=(object_bbox[3:] - object_bbox[:3])\n",
    ")\n",
    "\n",
    "bbox_center = (object_bbox[:3] + object_bbox[3:]) / 2\n",
    "bbox_size = object_bbox[3:] - object_bbox[:3]\n",
    "        \n",
    "data = {\n",
    "    # 'detections_list': detections_list,\n",
    "    'bboxes_3d_dict':{\n",
    "        object_name:{'center': bbox_center, 'size': bbox_size}\n",
    "    }\n",
    "}\n",
    "data.update(sensor_data)\n",
    "\n",
    "# call grasp detection service\n",
    "grasp_candidates: List[GraspMsg] = env.grasp_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually select a grasp from the list of grasps\n",
    "grasp_idx, weighted_score = select_grasp_by_preference(grasp_candidates, preferred_position=preferred_position, preferred_plane_normal=preferred_plane_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all grasp candidates with object point cloud \n",
    "grasp_o3d_meshes = []\n",
    "\n",
    "# rotate grasp orientation from gazebo gripper frame to anygrasp gripper frame\n",
    "rot_anygrasp2gazebo = np.array([[0,0,1],[0,1,0],[-1,0,0]])\n",
    "rot_gazebo2anygrasp = np.linalg.inv(rot_anygrasp2gazebo)\n",
    "\n",
    "for i, grasp_msg in enumerate(grasp_candidates):\n",
    "    quat = np.array([grasp_msg.grasp_pose.orientation.x, grasp_msg.grasp_pose.orientation.y, grasp_msg.grasp_pose.orientation.z, grasp_msg.grasp_pose.orientation.w])\n",
    "    rotation_matrix = R.from_quat(quat).as_matrix()\n",
    "    rotation_matrix = rotation_matrix @ rot_gazebo2anygrasp\n",
    "    translation = np.array([grasp_msg.grasp_pose.position.x, grasp_msg.grasp_pose.position.y, grasp_msg.grasp_pose.position.z])\n",
    "    # [score, width, height, depth, rotation_matrix, translation, object_id]\n",
    "    grasp = Grasp(\n",
    "        *[grasp_msg.grasp_score, grasp_msg.grasp_width, 0.02, grasp_msg.grasp_depth, rotation_matrix, translation, i]\n",
    "    )\n",
    "    grasp_o3d_meshes.append(grasp.to_open3d_geometry())\n",
    "    \n",
    "# change the selected grasp color to red \n",
    "grasp_o3d_meshes[grasp_idx].paint_uniform_color([1,0,0])\n",
    "\n",
    "o3d.visualization.draw_geometries([object_pcd, *grasp_o3d_meshes])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the grasp pose of white_and_pink_box with anygrasp\n",
    "pose_msg = env.parse_adaptive_shape_grasp_pose(object_name=object_name, preferred_position=preferred_position, preferred_plane_normal=preferred_plane_normal)\n",
    "env.publish_goal_to_marker(pose_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_gt_bbox('cabinet.handle_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get handle 0 position \n",
    "handle_0_position = env.get_object_center_position(\"cabinet.handle_0\")\n",
    "print(handle_0_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint = env.get_object_joint_info(obj_name=\"cabinet\", position=handle_0_position, type=\"any\")\n",
    "joint_axis = joint['joint_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.open_gripper(width=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preferred_position: Optional(np.ndarray), prefered gripper tip point position \n",
    "# preferred_approach_direction: Optional(np.ndarray), prefered gripper approach direction\n",
    "# preferred_plane_normal: Optional(np.ndarray), prefered gripper plane normal direction  \n",
    "\n",
    "grasp_pose = env.parse_adaptive_shape_grasp_pose(object_name=\"cabinet.handle_0\", preferred_position=handle_0_position, preferred_approach_direction=joint_axis)\n",
    "env.publish_goal_to_marker(grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.grasp(grasp_pose, pre_grasp_approach=0.05, tentative_depth_list=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a horizontal trajectory to open the drawer\n",
    "def move_in_direction(axis: np.array, distance: float):\n",
    "    current_pose = env.get_gripper_pose()\n",
    "    target_pose = Pose()\n",
    "    normalized_axis = np.array(axis) / np.linalg.norm(axis)\n",
    "    target_pose.position.x = axis[0] * distance + current_pose.position.x\n",
    "    target_pose.position.y = axis[1] * distance + current_pose.position.y\n",
    "    target_pose.position.z = axis[2] * distance + current_pose.position.z\n",
    "    target_pose.orientation = current_pose.orientation\n",
    "    env.move_to_pose(target_pose)\n",
    "    \n",
    "move_in_direction(axis=joint_axis, distance=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROS Python 3 (ipykernel)",
   "language": "python",
   "name": "ros_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
