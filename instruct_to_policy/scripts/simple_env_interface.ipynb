{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Failed to import pyassimp, see https://github.com/ros-planning/moveit/issues/86 for more info\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "from scipy.spatial.transform import Rotation as R \n",
    "import open3d as o3d \n",
    "# add catkin_ws context \n",
    "sys.path.append(\"/home/junting/catkin_ws/devel/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/junting/franka_ws/devel/lib/python3.9/site-packages\")\n",
    "\n",
    "from src.lmp import *\n",
    "from src.env.true_grounding_env import TrueGroundingEnv\n",
    "from src.config import cfg_tabletop\n",
    "import rospy \n",
    "import rospkg\n",
    "import jupyros as jr\n",
    "\n",
    "from std_msgs.msg import String, Header\n",
    "from geometry_msgs.msg import PoseStamped, Pose, Point, Quaternion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] [1703077824.241825, 0.000000]: init_node, name[/eval_code], pid[1624613]\n",
      "[DEBUG] [1703077824.243805, 0.000000]: binding to 0.0.0.0 0\n",
      "[DEBUG] [1703077824.244740, 0.000000]: bound to 0.0.0.0 43399\n",
      "[DEBUG] [1703077824.245363, 0.000000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077824.246316, 0.000000]: ... service URL is rosrpc://junting-PC:43399\n",
      "[DEBUG] [1703077824.247374, 0.000000]: [/eval_code/get_loggers]: new Service instance\n",
      "[DEBUG] [1703077824.248933, 0.000000]: ... service URL is rosrpc://junting-PC:43399\n",
      "[DEBUG] [1703077824.249866, 0.000000]: [/eval_code/set_logger_level]: new Service instance\n",
      "[DEBUG] [1703077824.388994, 909.826000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077824.393616, 909.830000]: connecting to junting-PC 52705\n",
      "[INFO] [1703077824.397855, 909.834000]: camera_left: Waiting for camera_left/color/camera_info...\n",
      "[DEBUG] [1703077824.405423, 909.841000]: connecting to junting-PC 52705\n",
      "[DEBUG] [1703077824.406861, 909.842000]: connecting to junting-PC 33927\n",
      "[INFO] [1703077824.940701, 910.341000]: camera_left: camera_left/color/camera_info received!\n",
      "[INFO] [1703077824.941996, 910.342000]: camera_left: camera_left/depth/camera_info received!\n",
      "[DEBUG] [1703077824.947736, 910.348000]: connecting to junting-PC 33927\n",
      "[INFO] [1703077824.949328, 910.349000]: camera_right: Waiting for camera_right/color/camera_info...\n",
      "[DEBUG] [1703077824.952793, 910.353000]: connecting to junting-PC 39379\n",
      "[DEBUG] [1703077824.954550, 910.355000]: connecting to junting-PC 39379\n",
      "[DEBUG] [1703077824.955004, 910.355000]: connecting to junting-PC 33927\n",
      "[INFO] [1703077825.484016, 910.851000]: camera_right: camera_right/color/camera_info received!\n",
      "[INFO] [1703077825.485639, 910.852000]: camera_right: camera_right/depth/camera_info received!\n",
      "[INFO] [1703077825.499032, 910.858000]: camera_top: Waiting for camera_top/color/camera_info...\n",
      "[DEBUG] [1703077825.507415, 910.865000]: connecting to junting-PC 43063\n",
      "[DEBUG] [1703077825.509084, 910.867000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077825.510218, 910.868000]: connecting to junting-PC 43063\n",
      "[DEBUG] [1703077825.510755, 910.868000]: connecting to junting-PC 33927\n",
      "[INFO] [1703077826.089772, 911.362000]: camera_top: camera_top/color/camera_info received!\n",
      "[INFO] [1703077826.093135, 911.364000]: camera_top: camera_top/depth/camera_info received!\n",
      "[DEBUG] [1703077826.095604, 911.365000]: ... service URL is rosrpc://junting-PC:43399\n",
      "[DEBUG] [1703077826.097708, 911.368000]: [/eval_code/tf2_frames]: new Service instance\n",
      "\u001b[0m[ INFO] [1703077826.123436019]: Loading robot model 'panda'...\u001b[0m\n",
      "[DEBUG] [1703077826.475260, 911.701000]: connecting to ('junting-PC', 51557)\n",
      "[DEBUG] [1703077826.496430, 911.722000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077826.497077, 911.724000]: connecting to junting-PC 38213\n",
      "\u001b[0m[ INFO] [1703077827.468861855, 912.635000000]: Ready to take commands for planning group panda_manipulator.\u001b[0m\n",
      "[DEBUG] [1703077828.077852, 913.206000]: connecting to junting-PC 52395\n",
      "\u001b[0m[ INFO] [1703077828.068236262, 913.200000000]: Ready to take commands for planning group panda_arm.\u001b[0m\n",
      "[DEBUG] [1703077828.085156, 913.216000]: connecting to junting-PC 45045\n",
      "[DEBUG] [1703077828.095031, 913.220000]: connecting to junting-PC 52395\n",
      "[DEBUG] [1703077828.100061, 913.220000]: connecting to junting-PC 38213\n",
      "[DEBUG] [1703077828.245717, 913.285000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077828.250596, 913.293000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077828.256718, 913.295000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077828.458377, 913.364000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077828.478405, 913.374000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077828.493130, 913.378000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077828.602282, 913.427000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077828.604421, 913.428000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077828.605054, 913.429000]: connecting to junting-PC 33927\n",
      "Gripper action clients ready\n",
      "Set up Franka API. Ready to go!\n",
      "[DEBUG] [1703077828.830518, 913.621000]: connecting to ('junting-PC', 45387)\n",
      "[INFO] [1703077828.831710, 913.622000]: Grasp detection: remote model service ready\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# initialize environment\n",
    "########################################\n",
    "rospy.init_node('eval_code', log_level=rospy.DEBUG)\n",
    "# get package root path \n",
    "pkg_root = rospkg.RosPack().get_path('instruct_to_policy')\n",
    "\n",
    "# setup environment\n",
    "env = TrueGroundingEnv(cfg_tabletop)\n",
    "# env.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth perception and 3D fusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D fusion \n",
    "from src.perception.scene_manager import SceneManager\n",
    "sensor_data = env.get_sensor_data()\n",
    "sensor_data['detections_list'] = [{},{},{}]\n",
    "\n",
    "scene_manager = SceneManager()\n",
    "scene_manager.update_fusion(sensor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cropped point cloud\n",
    "# drawer_bbox = env.get_3d_bbox('cabinet.drawer0')\n",
    "# drawer_pcd = scene_manager.scene_tsdf_full.crop_cloud(\n",
    "#     crop_center=(drawer_bbox[:3] + drawer_bbox[3:]) / 2,\n",
    "#     crop_size=(drawer_bbox[3:] - drawer_bbox[:3])\n",
    "# )\n",
    "# cabinet_bbox = env.get_3d_bbox('cabinet')\n",
    "# cabinet_pcd = scene_manager.scene_tsdf_full.crop_cloud(\n",
    "#     crop_center=(cabinet_bbox[:3] + cabinet_bbox[3:]) / 2,\n",
    "#     crop_size=(cabinet_bbox[3:] - cabinet_bbox[:3])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d \n",
    "# o3d.io.write_point_cloud(os.path.join(pkg_root, 'data', 'drawer.pcd'), drawer_pcd)\n",
    "# o3d.io.write_point_cloud(os.path.join(pkg_root, 'data', 'cabinet.pcd'), cabinet_pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick and Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_msg = env.parse_adaptive_shape_grasp_pose(\"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_mat = R.from_quat([pose_msg.orientation.x, pose_msg.orientation.y, pose_msg.orientation.z, pose_msg.orientation.w]).as_matrix()\n",
    "translation = np.array([pose_msg.position.x, pose_msg.position.y, pose_msg.position.z])\n",
    "\n",
    "depth = 0.05\n",
    "\n",
    "pregrasp_offset_local = np.array([0, 0, -0.15]).astype(np.float32)\n",
    "# predicted gripper center is 0.02m above the gripper tip\n",
    "approach_offset_local = np.array([0, 0, depth - 0.02 ]).astype(np.float32)\n",
    "pregrasp_position = translation + rot_mat @ pregrasp_offset_local\n",
    "approach_position = translation + rot_mat @ approach_offset_local\n",
    "\n",
    "pregrasp_pose = Pose(position=Point(*pregrasp_position), orientation=pose_msg.orientation)\n",
    "approach_pose = Pose(position=Point(*approach_position), orientation=pose_msg.orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.publish_goal_to_marker(pregrasp_pose)\n",
    "env.move_to_pose(pregrasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.publish_goal_to_marker(approach_pose)\n",
    "env.move_to_pose(approach_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close_gripper(width=0.05, force=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.attach_object(\"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_pose = env.parse_place_pose(object_name=\"apple\", receptacle_name=\"white_ceramic_plate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.move_to_pose(place_pose)\n",
    "env.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.detach_object(\"apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Drawer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jr.publish('/rviz/moveit/move_marker/goal_panda_hand_tcp', PoseStamped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "# env.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.get_obj_name_list()\n",
    "# [bbox.object_id for bbox in env.gazebo_gt_bboxes]\n",
    "env.get_3d_bbox(\"cabinet.handle_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_pose = env.parse_adaptive_shape_grasp_pose(object_name=\"cabinet.handle_0\")\n",
    "print(grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.publish_goal_to_marker(grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.grasp(grasp_pose)\n",
    "# env.move_to_pose(grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a horizontal trajectory to open the drawer\n",
    "grasp_position = np.array([grasp_pose.position.x, grasp_pose.position.y, grasp_pose.position.z])\n",
    "pull_position = grasp_position + np.array([0.2, 0, 0]).astype(float)\n",
    "pull_pose = Pose(position=Point(*pull_position), orientation=grasp_pose.orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.move_to_pose(pull_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different grasp depth \n",
    "pose_msg = env.parse_adaptive_shape_grasp_pose(object_name=\"apple\")\n",
    "\n",
    "rot_mat = R.from_quat([pose_msg.orientation.x, pose_msg.orientation.y, pose_msg.orientation.z, pose_msg.orientation.w]).as_matrix()\n",
    "translation = np.array([pose_msg.position.x, pose_msg.position.y, pose_msg.position.z])\n",
    "\n",
    "depth = 0.05\n",
    "\n",
    "pregrasp_offset_local = np.array([0, 0, -0.15]).astype(np.float32)\n",
    "# predicted gripper center is 0.02m above the gripper tip\n",
    "approach_offset_local = np.array([0, 0, depth - 0.02 ]).astype(np.float32)\n",
    "pregrasp_position = translation + rot_mat @ pregrasp_offset_local\n",
    "approach_position = translation + rot_mat @ approach_offset_local\n",
    "\n",
    "pregrasp_pose = Pose(position=Point(*pregrasp_position), orientation=pose_msg.orientation)\n",
    "approach_pose = Pose(position=Point(*approach_position), orientation=pose_msg.orientation)\n",
    " \n",
    "env.open_gripper()\n",
    " \n",
    "# env.publish_goal_to_marker(pregrasp_pose)\n",
    "env.move_to_pose(pregrasp_pose)\n",
    "# env.publish_goal_to_marker(approach_pose)\n",
    "env.move_to_pose(approach_pose)\n",
    "env.close_gripper(width=0.05, force=30)\n",
    "env.attach_object(\"apple\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grasp preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspnetAPI import GraspGroup, Grasp\n",
    "from grasp_detection.msg import Grasp as GraspMsg\n",
    "from src.grasp_detection.utils import select_grasp_by_preference\n",
    "\n",
    "# reload src.grasp_detection.utils \n",
    "import importlib\n",
    "importlib.reload(sys.modules['src.grasp_detection.utils'])\n",
    "from src.grasp_detection.utils import select_grasp_by_preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_name = \"white_and_pink_box\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] [1702551930.771895, 137.547000]: connecting to junting-PC 34991\n",
      "[DEBUG] [1702551930.774374, 137.549000]: connecting to junting-PC 34991\n"
     ]
    }
   ],
   "source": [
    "# ground truth preference of object \n",
    "\n",
    "# preferred_position is the center of the object\n",
    "preferred_position = env.get_object_center_position(object_name)\n",
    "\n",
    "# preferred_orientation is table surface \n",
    "preferred_plane_normal = np.array([0, 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1702551932.435929, 139.185000]: Sending perception data to grasp detection service\n",
      "[DEBUG] [1702551932.441211, 139.204000]: connecting to junting-PC 35057\n"
     ]
    }
   ],
   "source": [
    "# Manually call grasp detection model to get list of grasps\n",
    "\n",
    "object_bbox = env.get_3d_bbox(object_name)    \n",
    "sensor_data = env.get_sensor_data()\n",
    "\n",
    "object_pcd = scene_manager.scene_tsdf_full.crop_cloud(\n",
    "    crop_center=(object_bbox[:3] + object_bbox[3:]) / 2,\n",
    "    crop_size=(object_bbox[3:] - object_bbox[:3])\n",
    ")\n",
    "\n",
    "bbox_center = (object_bbox[:3] + object_bbox[3:]) / 2\n",
    "bbox_size = object_bbox[3:] - object_bbox[:3]\n",
    "        \n",
    "data = {\n",
    "    # 'detections_list': detections_list,\n",
    "    'bboxes_3d_dict':{\n",
    "        object_name:{'center': bbox_center, 'size': bbox_size}\n",
    "    }\n",
    "}\n",
    "data.update(sensor_data)\n",
    "\n",
    "# call grasp detection service\n",
    "grasp_candidates: List[GraspMsg] = env.grasp_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually select a grasp from the list of grasps\n",
    "grasp_idx, weighted_score = select_grasp_by_preference(grasp_candidates, preferred_position=preferred_position, preferred_plane_normal=preferred_plane_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all grasp candidates with object point cloud \n",
    "grasp_o3d_meshes = []\n",
    "\n",
    "# rotate grasp orientation from gazebo gripper frame to anygrasp gripper frame\n",
    "rot_anygrasp2gazebo = np.array([[0,0,1],[0,1,0],[-1,0,0]])\n",
    "rot_gazebo2anygrasp = np.linalg.inv(rot_anygrasp2gazebo)\n",
    "\n",
    "for i, grasp_msg in enumerate(grasp_candidates):\n",
    "    quat = np.array([grasp_msg.grasp_pose.orientation.x, grasp_msg.grasp_pose.orientation.y, grasp_msg.grasp_pose.orientation.z, grasp_msg.grasp_pose.orientation.w])\n",
    "    rotation_matrix = R.from_quat(quat).as_matrix()\n",
    "    rotation_matrix = rotation_matrix @ rot_gazebo2anygrasp\n",
    "    translation = np.array([grasp_msg.grasp_pose.position.x, grasp_msg.grasp_pose.position.y, grasp_msg.grasp_pose.position.z])\n",
    "    # [score, width, height, depth, rotation_matrix, translation, object_id]\n",
    "    grasp = Grasp(\n",
    "        *[grasp_msg.grasp_score, grasp_msg.grasp_width, 0.02, grasp_msg.grasp_depth, rotation_matrix, translation, i]\n",
    "    )\n",
    "    grasp_o3d_meshes.append(grasp.to_open3d_geometry())\n",
    "    \n",
    "# change the selected grasp color to red \n",
    "grasp_o3d_meshes[grasp_idx].paint_uniform_color([1,0,0])\n",
    "\n",
    "o3d.visualization.draw_geometries([object_pcd, *grasp_o3d_meshes])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1702556677.544106, 4876.112000]: Sending perception data to grasp detection service\n",
      "[DEBUG] [1702556677.550433, 4876.132000]: connecting to junting-PC 35057\n",
      "[DEBUG] [1702556679.132464, 4877.621000]: Waiting for rviz to update\n"
     ]
    }
   ],
   "source": [
    "# predict the grasp pose of white_and_pink_box with anygrasp\n",
    "pose_msg = env.parse_adaptive_shape_grasp_pose(object_name=object_name, preferred_position=preferred_position, preferred_plane_normal=preferred_plane_normal)\n",
    "env.publish_goal_to_marker(pose_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] [1703077835.437317, 919.205000]: connecting to junting-PC 33927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-1.1429746065220936, -0.005033182851874846, 1.4529604760174615],\n",
       " [0.06472280556051602, 0.4073600424866717, 0.02192639470308233])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_gt_bbox('cabinet.handle_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] [1703077835.714537, 919.425000]: connecting to junting-PC 33927\n",
      "[-1.14297333 -0.00503446  1.45295916]\n"
     ]
    }
   ],
   "source": [
    "# get handle 0 position \n",
    "handle_0_position = env.get_object_center_position(\"cabinet.handle_0\")\n",
    "print(handle_0_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] [1703077836.787005, 920.244000]: connecting to junting-PC 33927\n",
      "[DEBUG] [1703077836.800585, 920.253000]: connecting to junting-PC 33927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9.99999999e-01, -4.65130437e-05, -9.34212915e-07])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_object_joint_axis(obj_name=\"cabinet\", position=handle_0_position, type=\"any\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROS Python 3 (ipykernel)",
   "language": "python",
   "name": "ros_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
